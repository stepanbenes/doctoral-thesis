\chapter{Approximation of large data from the finite element analysis allowing fast post-processing}
\label{appendix-approximation}

The method of approximation of output from the Finite element method is based on premise, that computer memory and performance are limited. Without some kind of simplification or compression no program can efficiently process large amount of data generated by extensive finite element analysis. Following approximation method is also presented in \cite{Benes2016}.

%----------------------------------------------------------------------------------------
%	SECTION Idea
%----------------------------------------------------------------------------------------

\section{Idea}

The multigrid method \cite{XXX6-9} was the inspiration for this work. Multigrid method allows to solve partial differential equations using the hierarchy of domain discretizations. The main idea of multigrid method is to make the convergence of iterative method faster due to global corrections of error that is made from time to time on the coarser mesh. There are many variations of multigrid method. However, all of them need existence of mesh hierarchy that represents domain discretizations of different mesh sizes.

Basic steps of multigrid method are:

\begin{itemize}
    \item \textbf{Smoothing} -– The main goal of the smoothing phase is the high-frequency error reduction. It can be done e.g. by few iterations of the Gauss-Seidel method.
    \item \textbf{Restriction} -- Restriction of the residual from the finer to the coarser mesh.
    \item Solution of the coarse problem.
    \item \textbf{Prolongation} -- Interpolation and projection of the correction computed on the coarser mesh to the finer mesh.
\end{itemize}

The main problem with a mesh hierarchy is that often none is available. Only the finest mesh exists. The coarser meshes must be either generated directly by a mesh generator \cite{XXX-10, XXX-11} in the pre-processing phase or it must be created from the finer mesh. But generating coarser mesh from the finer one is very problematic or even impossible, because corresponding nodes between different levels should be preserved to be sure that multigrid method will work correctly without special modifications.

Therefore, it was decided to do visualization of the results from the finite element analysis on the fine mesh that is used for solution of FEM. Different methods of simplification and compression of the resulting data in space and time were developed and data were projected back to fine mesh. Results of the projection and comparison of methods are presented in this paper.

%----------------------------------------------------------------------------------------
%	SECTION Implementation
%----------------------------------------------------------------------------------------

\section{Implementation}

Even if the mesh hierarchy is generated, one of the obstacles for using the same multigrid techniques as are often used in the finite element analysis is that only one mesh hierarchy is available. That is sufficient for finite element solver, because this hierarchy is used to solve only one set of equations. However, in the post-processor it is necessary to display various kinds of data, such as temperature, displacements, stress, strain, etc. These quantities are scalars, vectors or tensors of second order. Components of vectors and tensors could be considered in post-processing as a scalar and therefore scalars will be dealt in the following text. Every scalar is represented in the finite element analysis by a set of discrete values computed in nodes or Gauss points, but in the strong formulation of a problem, it is a function. For graphical purposes, it is possible and often suitable to replace the set of discrete values by a continuous function. In the following text, the set of discrete values describing a scalar will be denoted as the discrete function or original function, but approximation of the discrete values for graphical purposes by continuous function will be called approximation function (shape functions used in FEM are not used here).

Approximation functions should be as simple as possible to be representable by a small set of parameters. Therefore, the domain of approximation function should respect the character of the discrete function. It can’t be the whole mesh, because one part of mesh could contain data replaceable by a simple linear function and other part could have much wilder character. It is therefore necessary to find alternative division of problem domain that will respect the shape of function in space and time better than the mesh hierarchy used in the multigrid method. Moreover, each quantity component must have its separately generated mesh hierarchy.

%----------------------------------------------------------------------------------------
%	SUB-SECTION Octree generation
%----------------------------------------------------------------------------------------

\subsection{Octree generation}

Domain space has to be divided into subdomains of the size which allows to replace discrete function with continuous, simpler, e.g. linear function that is easy to describe by fewer parameters. The goal is to automatically recognize areas in mesh, where the nature of function is smooth (the function is continuous together with the first derivatives and very coarse mesh can be used) and areas in which function rapidly changes its character (the first derivatives are large or the function is even discontinuous). These areas of interest become object of further subdivision, because for visualization purposes they need finer underlying mesh. For recursive division of 3D space the octree data structure is suitable (see Figure \ref{fig:octree-visualization}). The other spatial dividing data structures used in computer graphics were investigated, but octree seemed to be the best choice due to its hierarchical form and low average depth.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figures/appendix-approximation/figure1}
\decoRule
\caption[Octree visualization]{Octree visualization. Left: Recursive subdivision of a cube into octants. Right: The corresponding octree.}
\label{fig:octree-visualization}
\end{figure}

Basic overview of the decomposition and approximation procedure is in Listing \ref{alg:approximation}. At first whole mesh is inserted into one big cube -- octree root node. Then a condition that tells whether to divide current domain into eight subdomains is needed. Three conditions were designed. All have to be satisfied to proceed with decomposition.

\begin{enumerate}
    \item First condition specifies minimum number of finite element nodes to be represented by single octree cell. There are two reasons. Firstly, some specification of minimum number is necessary to compute approximation function, e.g. least square trilinear algorithm needs at least 8 values. Secondly, if the number is too small and the approximation function does not fit ideally, subdivision of the octree will be too subtle and memory consumption will easily exceed the case with no approximation applied at all.
    \item Second condition is based on maximal allowed relative error of chosen approximation function. Algorithm that replaces discrete data points with continuous approximation function also calculates relative error of the method. This number is then compared with some preset fixed value. According to the experiment results the most appropriate value of 1\% was chosen.
    \item Third condition describes maximum depth of octal tree. Each level of the tree exponentially increases memory consumption of data values stored in octree. Maximum depth is therefore artificially set to some acceptable value, e.g. 9. However, this depth should not be reached in common cases, it is ensured by condition 1.
\end{enumerate}

If all conditions are met, domain represented by the current octree node is divided into eight subdomains. Differences between original value of discrete function and value of approximation function in the same point are transferred to corresponding sub-nodes based on their location and whole process is recursively repeated in all octree sub-nodes. The difference $D_i$ of the $i$-th data value is defined by

\begin{equation}
D_i=V_i-\bar{V}_i, % or \overline ?
\end{equation}

where $V_i$ is the original function value in the $i$-th node and $\bar{V}_i$ is the value of approximation function in the same location as the $i$-th node.

Similar procedure -- passing residuals between mesh levels -- is applied in the multigrid method. Due to this approach the top levels of octree filter out main character of function (lower frequencies), bottom levels and leaves of the octree catch higher frequencies of function values.

%----------------------------------------------------------------------------------------
%	SUB-SECTION Approximation in space
%----------------------------------------------------------------------------------------

\subsection{Approximation in space}

Discrete values within an octree cell are replaced by a continuous function which is as simple as possible and can be represented in memory by a few parameters. It is therefore necessary to find suitable type of function and in the case of polynomial functions also the order of the function. Compression algorithm has to be very fast. Compromise between low error and memory consumption must be found. For the sake of simplicity at the beginning of the work the relations between neighboring octree nodes were neglected. Nodal values in each octree cell are approximated separately.

The compression procedure requires the surface representation of the mesh to be already created. The element connectivity and nodal coordinates has to be present in memory and accessible in constant $\mathrm{O}(1)$ time. Efficient methods to create this surface representation are described in Appendix \ref{appendix-mesh-visualization} and also in \cite{XXX}.

The procedure is reading the FEM results divided to data sets from the external file and then processing the data sets one by one. By a data set is meant primarily the array of floating-point numbers corresponding to one component of one quantity, e.g. $x$ component of displacement vector, temperature (which is scalar) or one component of stress tensor. Each floating-point number is the value of the quantity in single time step corresponding to one node or gauss-point. Whole array is loaded from file into computer memory, its values are distributed into growing octree and the approximation is calculated and saved in corresponding octree cells. After that the original data are deleted and algorithm continues with the next data component.

Compression has to be made on-the-fly during loading of data from the file to the memory between each data component. Starting compression after all results has been loaded to the memory would not make sense, because the main purpose of the compression step is to save overall memory consumption of the post-processor. Therefore, the format of data should ideally be designed in the way that each data component is separated in single data file or at least in one isolated data block in the file not mixed with other data. No particular order of data components is required. However, data formats used by common finite element software packages are usually designed in the way that the components of each quantity are grouped together. We rely mainly on GiD postprocess file format (\file{.res}) described in detail in \cite{XXX-12} where data are divided to blocks according to physical quantity and time step. Each block is the list of value tuples introduced by a node number (or element number in case of values in gauss-points), e.g. $x$, $y$ and $z$ component triplet for displacement vector in node $42$ in time step $3.0$. To avoid multiple passes through the data file the value tuples are cached and processed right after reading the whole data block.

\begin{lstlisting}[caption=Core of aproximation procedure,label=alg:approximation]
function OctreeInternalNode.InsertDataValues(dataValues, dataComponentId, depth, approximationMethod)
{
  // find approximation function and save it in current octree node
  approximation = ComputeApproximation(dataValues, dataComponentId, approximationMethod)
  DataCatalog[dataComponentId] = approximation
  // if condition #2 is met, propagate values to child nodes
  if (approximation.MaxRelativeError > MIN_RELATIVE_ERROR_TO_EXPAND)
  {
    // split residual values to octants based on data point positions
    foreach (dataValue in dataValues)
    {
      // calculate residual and distribute to octants according to position
      position = mesh.Nodes[dataValue.NodeId].Position
      residual = dataValue.Value - approximation.GetValueAt(position)
      octantIndex = getIndexOfOctantOnPosition(position)
      residuals[octantIndex].Add(new DataValue(residual, dataValue.NodeId))
    }
    foreach (octantIndex in range 1..8)
    {
      // if condition #1 is met, algorithm is recursively called on child octree node
      if (residuals[octantIndex].Count > max(MIN_LEAF_DATA_POINTS_COUNT, approximationMethod.MinNumberOfDataPoints))
      {
        // recursive call to InsertDataValues, if children[octantIndex] is LeafNode, than recursion is stopped
        children[octantIndex].InsertDataValues(residuals[octantIndex], dataComponentId, depth + 1, approximationMethod)
        // if child node is leaf, find out if expansion is needed
        if (children[octantIndex] is LeafNode)
        {
          // if condition #3 is met, algorithm can continue with octree node expansion
          if (depth < MAX_OCTREE_DEPTH - 1)
          {
            // if condition #2 is met, expand leaf node
            if (children[octantIndex].DataCatalog[dataComponentId].MaxRelativeError > MIN_RELATIVE_ERROR_TO_EXPAND)
            {
              children[octantIndex] = new OctreeInternalNode(children[octantIndex].LowerBounds, children[octantIndex].UpperBounds)
              children[octantIndex].InsertDataValues(residuals[octantIndex], dataComponentId, depth + 1, approximationMethod)
            }
          }
        }
      }
    }
  }
}

function OctreeLeafNode.InsertDataValues(dataValues, dataComponentId, depth, approximationMethod)
{
  // find approximation function and save it in current octree node
  DataCatalog[dataComponentId] = ComputeApproximation(dataValues, dataComponentId, approximationMethod)
}

function ComputeApproximation(dataValues, dataComponentId, approximationMethod)
{
  switch (approximationMethod)
  {
    case TrilinearInterpolation:
      approximation = DoLeastSquaresTrilinearInterpolation(dataValues)
    ...
  }
  // compute absolute error
  maxError = 0;
  foreach (dataValue in dataValues)
  {
    position = mesh.Nodes[dataValue.NodeId].Position
    error = dataValue.Value - approximation.GetValueAt(position)
    maxError = Max(maxError, Math.Abs(error));
  }
  approximation.MaxError = maxError;
  approximation.MaxRelativeError = maxError / GlobalDataRange[dataComponentId]
  return approximation
}    
\end{lstlisting}

After loading a data block, compression is started. Listing \ref{alg:approximation} contains pseudo-code of recursive procedure that is the core of the compression algorithm. Figure \ref{fig:octree-generation} contains overview of this algorithm in form of UML Activity diagram. The input is an array of nodal values in one component of one field defined on the mesh in single time step. In case of data stored in gauss-points the values has to be at first extrapolated to nodes using natural coordinates supplied in the data file. Nodal data are then passed as an input parameter \texttt{dataValues} to the function \texttt{InsertDataValues} that is called upon the octree root node which represents one big cube that surrounds the whole mesh. Each \texttt{dataValue} object is a structure consisting of floating-point number Value and integer \texttt{NodeId} that represents a key to the table of nodes in global mesh object. \texttt{InsertDataValues} is pure virtual function declared in abstract base class \texttt{OctreeNode} and its implementation differs in derived classes. Its implementation in \texttt{OctreeLeafNode} is straightforward and so follows description of its implementation in class \texttt{OctreeInternalNode}. Simplified class diagram of the key types involved in Listing \ref{alg:approximation} is shown in Figure \ref{fig:octree-class-diagram}.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figures/appendix-approximation/figure2}
\decoRule
\caption[Octree generation]{Octree generation algorithm in form of activity diagram.}
\label{fig:octree-generation}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figures/appendix-approximation/figure3}
\decoRule
\caption[Diagram of octree generation classes]{Class diagram of types involved in octree generation algorithm.}
\label{fig:octree-class-diagram}
\end{figure}

At first the algorithm computes parameters of continuous approximation function of discrete data values provided (variable \texttt{approximation}). In case of trilinear interpolation it uses least square method to calculate 8 parameters of a polynomial regression model and stores them in \texttt{DataCatalog} table which is a property of each octree node. Then the maximal relative approximation error is computed.

Approximation function for data values in the octree cell is assessed with the help of several metrics. First, absolute approximation error, which is the difference between the original nodal value and the value of approximation function, is evaluated in all nodes. Then, relative approximation error is obtained by dividing the absolute approximation error by global range of values (difference between global maximum and global minimum of original nodal values). The maximum relative approximation error in an octree cell is one of three parameters (see condition 2 above) that are used by the algorithm to decide whether to proceed with further subdivision of the octree cell. These three parameters control the overall quality of approximation, memory consumption and performance and need to be fine-tuned during testing on real-world data.

If the maximal approximation error is too high, the algorithm continues, calculates approximation error in each node and stores it in table residuals in relevant octant according to its position in current octree cell. \texttt{residuals} is a table of data value arrays and it is a local variable that will be disposed after each call to function \texttt{InsertDataValues} finishes. Algorithm then iterates over all child octants and checks for number of residuals assigned to them. If condition 1 stated above holds, algorithm is recursively called upon each child octree cell. If the octree cell is a leaf node, recursion is stopped and algorithm determines whether it should split current leaf octree cell into 8 sub-segments by checking conditions 2 and 3. In other words, if the current octree branch is not deep enough and maximal residual belonging to current child octree cell is higher than designated epsilon value, then this leaf cell is replaced with internal cell and function \texttt{InsertDataValues} is called upon this new \texttt{OctreeInternalNode} object. Residuals located in current octant are passed as an input to this function.

This continues until approximation of current data component is good enough in all octree cells.  When the algorithm finishes, original discrete data can be deleted, because the created octree structure with approximation functions in its nodes is all that is needed to reconstruct the original data. Then the algorithm can proceed with reading and processing next data set. Note that these operations are to a considerable extent independent and processing of data sets can be parallelized. However, if the same octree data structure is reused for multiple data sets, then the access to \texttt{DataCatalog} and octree node expansion has to be synchronized using standard locking mechanisms.

Also note that passing residuals of approximation instead of original data between octree levels is important, because it allows to describe the main character of function (lower frequencies) on top levels and details (high-frequency changes) on bottom levels of the octree. This design is inspired by the Multigrid method basic principles.

%----------------------------------------------------------------------------------------
%	SUB-SUB-SECTION Approximation functions
%----------------------------------------------------------------------------------------

\subsubsection{Approximation functions}

Various approximation functions were investigated and tested. Besides polynomial functions also Discrete cosine transform \cite{XXX-13} and Wavelet transform \cite{XXX-14} were considered. Since the data compression algorithm has to be very fast, simple polynomial approximation functions were preferred. They are summarized below:

\begin{itemize}
  \item \textbf{Mean value} -- A single value (average value) replaces the set of discrete values. Arithmetic mean was used during testing because it is fast to compute unlike the median. Also, it takes into account whole spectrum of values in contrast of the mode value that is the value that occurs most often in the collection. It is suitable in statistics where the measurement errors have to be excluded. However, in the case of the results from the FEM the user wants to see extremes in data and these outlying results should be rather highlighted instead of truncated. That is the reason why is neither the arithmetic mean nor other statistically estimated mean value suitable for this purpose. Mean value approximation diagram is depicted in Figure \ref{fig:mean-value-approx}.

  \begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{figures/appendix-approximation/figure4}
  \decoRule
  \caption[Mean value approximation diagram]{Mean value approximation diagram. Dashed lines denote octree division process. Shorter the line the deeper subdivision represents. Mean value is not suitable because of high errors and discontinuities between approximation cells. $v$ stands for function value and $x$ for spatial dimension.}
  \label{fig:mean-value-approx}
  \end{figure}

  \item \textbf{Regression} -- Finds a polynomial that models relationship between a scalar dependent variable and one or more explanatory (independent) variables. In three-dimensional problem there are three independent variables. Polynomial regression models are often fitted using the least squares method. The implementation used in this work is based on solving linear system of equations using LU decomposition. Key thing is that the size of the system does not depend on the number of data values, but on the number of approximation function parameters. Therefore, the algorithm has linear computational complexity and scales well. Several polynomials were tested. In the functions below $x$, $y$, $z$ are spatial coordinates, $c_i$ are parameters which determine the shape of the polynomial and $v$ is the function value.

  \begin{itemize}
    \item \textbf{Linear} -- Hyperplane, only four parameters per octree cell. Value $v$ in the point with coordinates $x$, $y$, $z$ is computed using linear interpolation function in the form
    
    \begin{equation}
    v=c_{1}x + c_{2}y + c_{3}z + c_{4}.
    \end{equation}
    
    Figure \ref{fig:octree-creation} contains example of creation of octree node hierarchy driven by this function.
    
    \item \textbf{Quadratic} -- Parametric shape models known as Hyperquadrics. They have too many parameters per cell (10) and are not suitable to capture continuity between octree cells. Value v in the point with coordinates $x$, $y$, $z$ is computed using quadratic interpolation function in the form

    \begin{equation}
      v=c_{1}x^2 + c_{2}y^2 + c_{3}z^2 + c_{4}xy + c_{5}xz + c_{6}yz + c_{7}x + c_{8}y + c_{9}z + c_{10}.
    \end{equation}

    \item \textbf{Trilinear} -- 8 parameters, the best compromise, consistent with neighboring octree cells, almost “seamless” transitions between octree cells. Also used in the FEM. Value $v$ in the point with coordinate $x$, $y$, $z$ is computed using trilinear interpolation function in the form
    
    \begin{equation}
      v=c_{1}xyz + c_{2}xy + c_{3}xz + c_{4}yz + c_{5}x + c_{6}y + c_{7}z + c_{8}.
    \end{equation}

    The least squares method is applied to find parameters $c_{1},...,c_{8}$. The problem is solved by minimizing the sum of squared residuals $G$ of the linear regression model

    \begin{equation}
      G = \sum_{i=1}^{N}(v_i - (c_{1}x_{i}y_{i}z_{i} + c_{2}x_{i}y_{i} + c_{3}x_{i}z_{i} + c_{4}y_{i}z_{i} + c_{5}x_{i} + c_{6}y_{i} + c_{7}z_{i} + c_{8}))^2,
    \end{equation}
    
    where $N$ is number of values which are interpolated. When the parameters of interpolation are known, value in any point of the approximated volume can be found simply by providing $x$, $y$, and $z$ coordinates of the point in the equation.
    
    \item \textbf{Tri-quadratic} -- Too many describing parameters with no significant benefit over trilinear form.
    
    \item \textbf{Quadrilinear form} -- Generalized trilinear form, extended by temporal dimension, only theoretical option, not implemented.
    

  \end{itemize}

\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{figures/appendix-approximation/figure5}
\decoRule
\caption[Octree creation]{Octree creation example based on linear approximation error.}
\label{fig:octree-creation}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{figures/appendix-approximation/figure6}
\decoRule
\caption[Nodal value computation]{Nodal value computation diagram.}
\label{fig:nodal-value-computation}
\end{figure}

Figure \ref{fig:nodal-value-computation} depicts computation of nodal value via traversing octree from the root to the leaves and simultaneously summing up approximation errors. Root node of the octree contains all data components in all time steps where data value of an arbitrary element node can be computed. If an approximation is not sufficiently accurate in current octree node, correction can be made with the help of data stored in lower levels of the octree and summing up corrections together with initial value to compute final value for the node.

%----------------------------------------------------------------------------------------
%	SUB-SUB-SECTION Results
%----------------------------------------------------------------------------------------

\subsubsection{Results}

\chapter{FEA data management}

Together with growing complexity of finite element calculations, the importance of management of data produced by the calculations is increasingly emphasized in both industrial and research communities. Information is often shared between multiple users, moved from one computer to another, and further transformed to enable different views over the data. Some definition of persistent and standard representation of the data is therefore required as well as the corresponding data access system architecture that allows to query the data.

\section{Data management system architecture}

The prototype implementation of the FEA data management system is designed as a collaborative framework that can be accessed by users from different client devices. Figure \ref{fig:FEA-architecture} depicts the schema of the system architecture. The system consists of several independent modules. The FEM calculation itself runs on a remote server as one of micro-services\footnote{Microservices is a service-oriented architectural style that structures an application as a collection of loosely coupled services. The benefit of decomposing an application into different smaller services is that it improves modularity and makes the application easier to understand, develop, test, and deploy.} along with a mesh generation service, a results processing service, etc. These services are controlled by an application service that provides interface to client applications in form of REST API\footnote{Representational state transfer (REST) is a way of providing interoperability between computer systems on the Internet. API stands for Application Programming Interface and describes a proper way for a developer to write a program requesting services from the software exposing the API. RESTful API takes advantage of verbs provided by HTTP protocol, i.e., GET, POST, PUT, DELETE, etc.}.

The architecture design relies on an abstraction provided by Platform-as-a-Service\footnote{Platform as a Service (PaaS) is a category of cloud computing services that provides a platform allowing customers to develop, run, and manage applications without the complexity of building and maintaining the complex infrastructure. PaaS can be delivered in two ways: as a public cloud service from a provider, where the consumer controls software deployment with minimal configuration options, and the provider provides the networks, servers, storage, operating system (OS), middleware (e.g., .NET runtime, Node.js, etc.), database, and other services to host the consumer's application; or as a private service inside the firewall in an organisation's on-premises data center.} computing model. No service component is tied directly to a specific machine. Hardware resources are allocated when they are needed by a service infrastructure controller. This makes the scaling and deployment of components easier and allows to focus on the problem domain instead of solving server configuration and networking issues.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/chapter-data-management/FEA-architecture}
    \decoRule
    \caption{FEA system architecture.}
    \label{fig:FEA-architecture}
\end{figure}

The system contains two types of data storage. The relational-database type of storage is intended to store basic project-related data such as description of simulations, links to the simulation resources, information about the owner and other colaborating users, etc. The input to FEA -- geometrical model, attribute assignments, and analysis parameters -- can also be stored in a relational database, eventhough, storing this complex type of information in the SQL database is questionable and has its drawbacks\footnote{Relational databases are primarily designed to support mutations of the data, while the input model to FEA, after it is created, does not need to be changed. Relational databases are not easily scalable. They have fixed schema and tables often do not map to objects well and some object-relational mapper must be used. Also, the nature of relational databases often leads to data for different tenants, users, and projects being mixed together in the same tables, which complicates the management of data and could cause security issues. The use of a NoSQL database or a simple blob storage should be considered as an alternative if the character of the application data does not fit well into the relational database model.}.

The second type of storage is the blob storage\footnote{Blob storage is also referred to as Object storage. It is a service for storing large amounts of unstructured object data, that can be accessed over the network via HTTP or HTTPS. A blob can be any type of text or binary data, such as document or media files. Blob is an acronym for Binary Large OBject.} used to hold temporary files being the input or the output of particular components, especially the mesh generator and the FEM solver. The system is designed to be independent of the solver and mesh generator components, therefore this intermediate step of converting the input to proprietary file format that the components understand is necessary. In the future, it is possible to expect a gradual transition from the file-based approach to the direct connection to the database and query the input model directly. Also, the output of the calculation could be saved directly in the proposed format to represent the results in post-process-ready form.

Workflow diagram in Figure \ref{fig:FEA-workflow} helps to visualize the sequence of FEA steps and the transfer of data between the service components. It also reveals the basic design principle behind the microservice architecture -- Separation of concerns\footnote{Separation of concerns -- design principle for separating system into distinct sections, such that each section addresses a separate concern.}. The vertical bars denote computational intensive tasks performed by the service components. The client side in the diagram represents the presentation layer of the FEA system that the user directly interacts with. In the presentation layer, also called \textit{frontend}, there is spent the vast majority of time by users doing pre- and post-processing of data (which is not depicted in the diagram). The web API service, also called \textit{backend}, is the key component that assigns work to other components. It serves as an controller for a running analysis and as an interface between the data stored in databases and the client applications.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/chapter-data-management/FEA-workflow}
    \decoRule
    \caption{FEA system workflow.}
    \label{fig:FEA-workflow}
\end{figure}

The prototype implementation of the data management system follows the schema and the workflow depicted in Figures \ref{fig:FEA-architecture} and \ref{fig:FEA-workflow}. The difference is that the pre-processing phase is currently excluded. The focus of the work presented in this thesis is primarily on the post-processing features and the representation of results. Therefore, the results from the existing FEM solver are uploaded into the system and the system converts them to the internal representation suitable for post-processing. To test the prototype implementation of the data management system, two client applications are created. The first is the feature-rich desktop post-processor with the support for Microsoft Windows and Linux operating systems.

The second is the simple web application that provides basic control over an analysis and basic post-processing capabilities. Its purpose is mainly to demonstrate the benefits of proposed format for storage of results when post-processing complex FEA. Its web-based implementation allows for truly cross-platform experience without the need for installation and it allows to access the analysis data even from low-end mobile devices.


\section{Storage format for results}
\label{sec:storage-format}

The conceptual model presented in Figure \ref{fig:FEA-db-schema} can be naturally extended with the entities representing the results of the simulations. The project-based data model enhanced with the representation of simulation results is depicted in Figure \ref{fig:FEA-db-schema-results} as ER diagram. The corresponding class diagram is depicted in Figure \ref{fig:results-class-diagram}, which describes the object representation of the Solution entity. It is physically representated either by a JSON file in a local file system or by several tables in a relational database.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/chapter-data-management/FEA-database-schema-only-results}
    \decoRule
    \caption[Database schema for FEA with results representation only.]{Database schema for FEA with results representation only (without the input model).}
    \label{fig:FEA-db-schema-results}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/chapter-data-management/results-class-diagram}
    \decoRule
    \caption{Object representation of simulation results.}
    \label{fig:results-class-diagram}
\end{figure}

The simulation results are represented by the Solution entity, which holds a structure consisting of the results from the FEM solver that are converted to the form suitable for post-processing. The structure has the form of a tree. A node of the tree is represented by the Layer entity. A layer is an association of a mesh and corresponding result fields and other attributes. The use of a tree structure allows to preserve the relations between the parent layers and the layers that are derived from them. The mesh that is referenced by a layer need not be the same as the mesh used as the input mesh to the FEM solver. It could be modified by the solver during the calculation, e.g., due to the use of adaptive finite element techniques \footnote{Adaptive finite element methods can automatically refine, coarsen, or relocate a mesh to achieve a solution having a specified accuracy.}. Also, the resulting mesh can be further modified to facilitate the post-processor implementation, e.g., the surface representation of a 3D mesh can be generated or a number of cross-sections can be created at uniform intervals to provide a look inside the mesh. Generally, multiple views on the results can be prepared in advance before the user even starts to investigate the results.

The concept of layer is not new. It is used in existing implementations of the post-processors in FEA software packages (often named \textit{filter} instead of layer), to represent a view on the results. However, the layers (visual filters) are usually generated on demand by specific user request and they are not kept in a persistent storage. The proposed storage format for results is built on top of the layer tree structure directly, which allows the layers to be accessed later on, even on a different device, or shared by multiple users working on the same project.

In the prototype implementation of the FEA data management system, it is supposed that the FEM solver uses its own proprietary format to represent the results from the simulation. As the system is designed to be independent of individual components, the Results converter component converts the results from the FEA solver into the standardized layer-based format suitable for post-processing. The specification of the format follows.

\subsection{Format specification}

All the documents that participate in the storage format are presented in JSON format. JSON is the today's standard for data transport in web technologies and also as a storage format in growingly popular NoSQL databases\footnote{NoSQL databases (NoSQL originally stands for non-SQL, today often for Not-only SQL) provide a way to store and query the data that is modeled in means other than the tabular relations used in relational (SQL) databases, e.g., key-value pairs, object graphs, or documents. The purpose is to offer better scalability, availability, and flexibility of the database schema. Examples of NoSQL databases: MongoDB, Redis, or Azure Cosmos DB.}. It is a consise textual format easily readable both for human and for computer. However, the storage format is not tightly coupled with JSON, data can be encoded in another structured format, such as XML. As mentioned above in the text, there are two types of locations the data can be stored in -- \textbf{remote} and \textbf{local}. Both locations are supported in the prototype implementation. In either case, the key part of the format is the solution document. An example of the solution document is given in Listing \ref{lst:solution.json}. In case of remote storage, the solution document is stored in a relational database as part of the project-based data representation shown in Figure \ref{fig:FEA-db-schema-results}, while the rest of documents is stored in a blob storage as group of JSON documents. In case of local storage, all documents, including the solution document, are stored in a folder as JSON files in local file system on a personal computer on which the results are post-processed.

As can be seen in the example of the solution document in Listing \ref{lst:solution.json}, each layer is assigned a unique identifier, specifically a GUID\footnote{Globally unique identifier (GUID) or Universally unique identifier (UUID) is a 128-bit number used often as an identifier of information. GUIDs are for practical purposes unique, without depending for their uniqueness on a central registration authority or coordination between the parties generating them. While the probability that a GUID will be duplicated is not zero, it is close enough to zero to be negligible. GUID is therefore often used as the type of a primary key in databases.} number. A GUID in its textual representation is also used to unambigously determine the location of layer documents. In case of a solution stored locally, a GUID is used as the name of the folder the related layer documents are stored in. For remote solutions, a GUID is used as a part of a URL when requesting resources from a database or a blob storage.

% TODO: describe properties in solution document? Id, ProjectName, Location, Results, Layers, Layers.Id, Layers.Name, Layers.FilterType, Layers.Children

Data in each layer are stored in four types of documents. All documents are identified by the layer id and by its index within the layer (except Summary document that does not need an index as it exist in one instance per layer).
\begin{itemize}

    \item \textbf{Summary document} contains all the descriptive information about a layer. An example of a summary document in JSON format is presented in Listing \ref{lst:summary.json}. Besides a unique id, a layer has its name, which the user can choose arbitrarily, otherwise it is automatically derived from the \code{Filter} property. \code{Filter} property describes the parameters of the transformation applied to the parent layer to obtain the current layer. \code{ParentId} property contains the GUID assigned to the parent layer. The topmost root of the layer tree has no parent. Therefore, its \code{ParentId} property is null as well as \code{Filter} property. Default name for the root layer is ``master''\footnote{The format allows the existence of multiple root layers, but it turns out that it is not necessary in practice. In the vast majority of cases, there is a single root layer and it is called ``master''.}.

    \code{Meshes} property holds the collection of mesh descriptors. A mesh descriptor serves as an reference to an actual mesh document related to a layer. Each mesh in a layer is assigned an index. It is a number that uniquely identifies the mesh within the layer. \code{TimeSteps} property of each mesh contains the list of time steps for which the mesh is defined. In usual case, there is only one mesh for all time steps. In some cases, however, there can be different mesh for each time step. Application of deformation filter to a layer yields a derived layer that contains the same number of meshes as is the number of time steps, because the deformed meshes are generated by translating the nodes of the parent mesh by displacements calculated for each time step. Even the master layer can be composed of multiple meshes, e.g., when representing the results from a simulation of construction stages. The time step number must be a unique decimal number as it serves as an identifier.
    
    Each mesh has optional set of attributes. An attribute is an umbrella term for additional information assigned to mesh entities. It is usually a property of the input model that is propagated to the results as it can be interesting during post-processing. The most common attribute is the material number that is assigned to each element of the mesh.

    \code{Fields} property contains a dictionary of result descriptors. Each field descriptor is introduced by the name of the field imported from the FEM results. Field can be composed of one or more components. Similarly, each component descriptor is identified by its name and enumerates the time steps in which the component is defined. Each time step descriptor contains the index of the corresponding result document as well as the index of the mesh document. Each result document always contains data for only one data component. However, the format allows that the data from multiple time steps can be gathered and stored in a single result document. The compression can be then applied on the range of time steps as a whole to achive better compression ratio. Therefore, to recover an arbitrary data component located either in a local or in a remote storage, the post-processor needs just a triplet of identifiers -- the layer id, the index of a result document, and the time step.

    \item \textbf{Mesh document} contains the geometric representation of a finite element mesh. An example of a mesh document in JSON format is presented in Listing \ref{lst:mesh.json}. Positions of the nodes are encoded in \code{PointCoordinates} property\footnote{Note that the terms \textit{node} and \textit{element} are internally referred to by more general terms \textit{point} and \textit{cell}.\label{foot:points-cells}}. Position of each node is a vector, whose components are floating-point numbers. Number of vector components is equal to the number of dimensions of the mesh. Vector components are flattened into a one dimensional array and converted to text using binary-to-text encoding (more about encoding in Section \ref{subsec:encoding}). \code{CellConnectivity} property\footnotemark[\getrefnumber{foot:points-cells}] contains encoded list of indices of element nodes that point to the coordinate array. The number of nodes per element can be retrieved by decoding \code{CellTypes} property, in which the types of all elements are stored. The supported element types along with their identifiers are depicted in Figure \ref{fig:supported-cell-types}. The identifiers are 8-bit unsigned integers (bytes) and the values match the definition of cell types in VTK file format \cite{VTK2015} to provide basic compatibility and to ease the conversion from the VTK format.
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.9\textwidth]{figures/chapter-data-management/supported-cell-types}
        \decoRule
        \caption[Element types supported in storage format.]{Element types supported in storage format. The values used for encoding element types in CellTypes array are shown in parentheses. The illustrations of elements are taken from \cite{VTK2015}.}
        \label{fig:supported-cell-types}
    \end{figure}
    
    Properties \code{Center} and \code{Radius}, eventhough their values can be calculated from the coordinate array, were added as an performance optimization for a post-processor since it is usually needed to normalize the mesh dimensions before the first rendering.

    \item \textbf{Attribute document} serves as a container for additional information assigned to mesh entities, e.g., material id of each finite element. An example of an attribute document in JSON format is presented in Listing \ref{lst:attribute.json}. \code{FieldName} property contains the name of the attribute. The schema of Attribute document is similar to Result document. The only difference between the two is that an attribute document is not tied to any time step, but directly to a mesh. Therefore, Attribute document does not need \code{TimeSteps} property. An attribute is defined in all time steps in which the referenced mesh is defined.

    \item \textbf{Result document} is the document that contains the result fields from FEM. An example of a result document in JSON format is presented in Listing \ref{lst:result.json}. Result document is usually the most memory-consuming component of the storage format and it is therefore designed to support compression of data to reduce its size. There are also many options to partition the data into smaller groups. The largest granularity is achieved when the data corresponding to a single time step is stored in a single document, which allows for the lowest latency when transfering the document from the storage to the post-processor, in particular when the data are stored on a remote machine. On the other hand, the better reduction of overall size can be achieved when the data for all time steps of a field component are stored in a single document, which usually leads to better compression ratio as the compression method can find more redundancies in the data. There is also a compromise between the two approaches -- to divide the time steps into multiple groups of equal or distinct sizes. This is usually connected with the input of the user who specifies the collection of key time steps of the analysis. If the key time steps are carefully chosen, the compression ratio and/or error can be even better compared to the previous case. The selected time steps are listed in \code{TimeSteps} property.

    The value of \code{FieldName} property identifies the name of a physical field in the results from FEM, such as ``Displacements'', ``Stress'', ``Strain'', or ``Temperature''. The components of vector or tensor fields are identified by \code{Component\-Name} property. Scalar fields, which consist of a single component, have its \code{Component\-Name} property left empty or set to some generic name, such as ``value''. The value of \code{Location} property determines which type of mesh entity the data relates to. Its value can be either ``Points'', ``CellPoints'', or ``Cells'', which relates to nodes, element nodes, and elements, respectively. The storage format does not support the data located in integration points (Gauss points) as the storage format is intended to simplify the work for post-processor as much as possible and the extrapolation from integration points is non-trivial task. The data must be therefore transformed to one of the supported locations before converting to the storage format. Various extrapolation strategies exist and it is up to the user to select the one that is appropriate for the task. The default extrapolation strategy in the implementation of the results converter component is the projection of a value in a Gauss point to the nearest element node.

% TODO: briefly describe what is Gauss point extrapolation, enumerate examples of such strategies, ...

    The data of the field component can be optionally compressed. Then it is converted to text using a binary-to-text encoding method and stored as the value of \code{Data} property. The parameters of the compression method are contained in \code{Compression} property and the parameters of the encoding used are in \code{Encoding} property (for details see sections \ref{subsec:compression} and \ref{subsec:encoding}).

\end{itemize}

At first glance the format seams to be overcomplicated. The data are scattered throughout a large number of documents. There are various types of documents with different schema, some information is duplicated, etc. However, the format is carefully designed to allow efficient and simple implementation of a post-processor while enabling the use of compression to significantly reduce the storage size of the results if needed. A post-processor should be able to easily decode the data and display it immediately, without the need for additional transformation, sorting, or caching. E.g., there is one-to-one mapping of the data in a result document to a mesh to be able to use the decoded data array directly as an OpenGL buffer in the graphics card. Also, the fact that the data are stored in a small structured documents of a known schema enables to index the data by a database management system and also to create efficient queries over the data. As a side effect of the data fragmentation, the resulting latency is being very low, i.e., the delay between the user request and the data being rendered on a screen is small (which allows real-time creation of animations).
